{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$\\newcommand{\\vec}[1]{{\\bf #1} } \n",
    "\\newcommand{\\real}{\\mathbb{R} }\n",
    "\\newcommand{\\expect}[1]{\\mathbb{E}[#1] }\n",
    "\\DeclareMathOperator*{\\argmin}{arg\\,min}\n",
    "\\DeclareMathOperator*{\\argmax}{arg\\,max}\n",
    "\\newcommand{\\E}{\\mathbb{E}}$$\n",
    "<img src=\"imgs/logo.png\" width=\"85%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5th Summer School on Computational Interaction\n",
    "\n",
    "## Part 2: Introduction to Bayesian Optimization in HCI\n",
    "\n",
    "---\n",
    "### Antti Oulasvirta and Tomi Peltola / Aalto University \n",
    "\n",
    "* antti.oulasvirta@aalto.fi / [Aalto User Interfaces group](http://userinterfaces.aalto.fi)\n",
    "* tomi.peltola@aalto.fi / Probabilistic Machine Learning group / [Homepage](http://www.tmpl.fi)\n",
    "\n",
    "[Original slides from a lecture at Aalto by Tomi Peltola](http://www.tmpl.fi/bayesian-optimization/slides.Rmd)\n",
    "\n",
    "[Updated version for CHI2019](https://github.com/johnhw/chi_course_2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning goals\n",
    "\n",
    "This is practically oriented lecture for HCI researchers and practitioners. After this lecture and the exercises, you should\n",
    "\n",
    " 1. understand the basics of Bayesian optimization and its applications in HCI,\n",
    " 2. be able to assess when it can be a useful tool and when not,\n",
    " 3. know how to use the GPyOpt Python package for your own applications.\n",
    "\n",
    "\n",
    "## Table of contents\n",
    "\n",
    " 1. Introduction\n",
    " 2. Bernoulli bandit\n",
    " 3. Bayesian optimization \n",
    " 4. Acquisition functions\n",
    " 5. Application example\n",
    " 6. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. Introduction\n",
    "\n",
    "<p>\n",
    "<div class=\"alert alert-block alert-success\"> \n",
    "<h3>In-class exercise.</h3> \n",
    "<br>\n",
    "Ask your friend to pick two or three favorite colors. You would like to figure out what they are, **but** you can only ask about one color at a time. When asked about a color, the friend must tell how liked it is on a scale from 1 to 5 (best). If you only have 8 questions, **how** should you choose which color to ask?</div>\n",
    "</p>\n",
    "\n",
    "\n",
    "## Overview \n",
    "Bayesian optimization is a modern approach to **global optimization**. It is robust and sample-efficient and well-suited for noisy, expensive evaluative functions. It uses a **surrogate model** for approximating the model fit across the parameter space.  Posteriori probability provides an intuitive quantification of acquired knowledge of the best parameter values given the available observation data. Another core idea is to use an **acquisition rule** for selecting which parameter values are used for generating predictions, based on the surrogate model. Inference is performed through a sequence of optimization rounds. \n",
    "\n",
    "Recipe:\n",
    "\n",
    "- At the beginning of each round, the acquisition rule is used to select a set of parameter values that will be used to generate predictions. The locations are balanced such that they cover both unknown regions of the parameter space (**exploration**) and regions with high probability to lead to good model fit (**exploitation**). \n",
    "- After predictions have been generated at each location, the surrogate model is updated based on the observed model fits, and the next optimization round begins. \n",
    "- The final parameter estimates are often chosen to be the parameter values that lead to best predicted model fit on average.\n",
    "\n",
    "[Visual overview](imgs/bo-overview.png).\n",
    "Source: https://towardsdatascience.com\n",
    "\n",
    "**Compare: Grid search** assumes that the optimal parameter values are contained within some bounded region of the parameter space. Then divide this bounded parameter space into a large number of smaller cells, often by using an even grid. Then, for each grid cell, a dataset is generated using the parameter values at the cell, and finally the parameter values that yielded the best model fit are used as the final estimate.\n",
    "\n",
    "## Problem\n",
    "\n",
    "Find the minimum of a function $f(x)$ within some bounded domain $\\mathcal{X} \\subset \\mathbb{R}^D$:\n",
    "\n",
    "$$x^* = \\argmin_{x \\in \\mathcal{X}} f(x)$$\n",
    "\n",
    "**How would you solve this?**\n",
    "\n",
    " * Hand-tuning / trial and error,\n",
    " * random search,\n",
    " * grid search,\n",
    " * gradient descend,\n",
    " * evolutationary algorithms,\n",
    " * different types of programming (linear, integer, etc.),\n",
    " * ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application - A/B testing\n",
    "\n",
    "But what if... $f$ \n",
    "\n",
    " * can only be evaluated implicitly,\n",
    " * with a lot of noise, and\n",
    " * is costly to evaluate.\n",
    " \n",
    "For example, optimize for click-through rate, retention time, or purchases, implicitly measuring user satisfaction, interest, or revenue of different version of a web site.\n",
    "\n",
    "By choosing conditions wisely, Bayesian optimization can converge to a good design quicker and avoid contaminating users with potentially bad designs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application - Computational design\n",
    "\n",
    "But what if ... $f$ \n",
    "\n",
    " * is a black-box (e.g., contains human judgement),\n",
    " * with noisy and expensive/slow evaluations,\n",
    " * and multi-modal.\n",
    "\n",
    "For example, optimizing parameters for procedural animation generation by asking humans to rate generated examples.\n",
    "\n",
    "<div class=\"center\">\n",
    "<img src=\"imgs/anim.png\" style=\"width: 50%\" />\n",
    "</div>\n",
    "\n",
    "<div style=\"font-size: 10px;\"><a href=\"https://dl.acm.org/citation.cfm?id=1921443\">[image: Brochu et al., 2010]</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application - Adaptive interfaces\n",
    "\n",
    "But what if ... $f$ \n",
    "\n",
    " * is based on an implicit signal from human,\n",
    " * with noisy and expensive/slow evaluations.\n",
    "\n",
    "For example, optimizing step rate to minimize metabolic cost.\n",
    "\n",
    "<div class=\"center\">\n",
    "<img src=\"imgs/wearable_devices.png\" style=\"width: 70%\" />\n",
    "</div>\n",
    "\n",
    "<div style=\"font-size: 10px;\"><a href=\"https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0184054\">[image: Kim et al., 2017]</a></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application - Inverse modeling\n",
    "\n",
    "But what if ... $f$ \n",
    "\n",
    " * contains a parametric simulator,\n",
    " * with noisy and expensive/slow evaluations.\n",
    "\n",
    "For example, fitting parameters of cognitive simulators to experimental data.\n",
    "\n",
    "<div class=\"center\">\n",
    "<img src=\"imgs/abc2.png\" style=\"width: 60%\" />\n",
    "</div>\n",
    "\n",
    "<div style=\"font-size: 10px;\"><a href=\"https://dl.acm.org/citation.cfm?doid=3025453.3025576\">[image: Kangasraasio et al., 2017]</a></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application - Others\n",
    "\n",
    " * Recommender systems\n",
    " * Sensor networks\n",
    " * AutoML: automatic tuning of machine learning models\n",
    " * Robotics and reinforcement learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The computational problem\n",
    "\n",
    "**Problem:** Find the minimum of a function $f(x)$ within some bounded domain $\\mathcal{X} \\subset \\mathbb{R}^D$:\n",
    "\n",
    "$$x^* = \\argmin_{x \\in \\mathcal{X}} f(x)$$\n",
    "\n",
    "**Challenges**\n",
    " * $f$ is a black-box that we can only evaluate point-wise, \n",
    " * $f$ can be multi-modal,\n",
    " * $f$ is slow or expensive to evaluate,\n",
    " * evaluations of $f$ are noisy,\n",
    " * $f$ has no gradients available (can be used if available).\n",
    "\n",
    "** Basic idea of BO **\n",
    "\n",
    "We want to find the minimum with small number of evaluations of $f$. Solution:\n",
    "\n",
    " 1. Construct a tractable **statistical surrogate model** of $f$.\n",
    " 2. Turn the optimization problem into **a sequence of easier problems**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2. Bernoulli bandit\n",
    "\n",
    "*To link Bayesian optimization to Bayesian statistics, we look at a simpler, so-called bandit problem first.*\n",
    "\n",
    "**Task**: Conduct an A/B test to find which of two versions of a Web ad is better; that is, which ad gets most clicks.\n",
    "\n",
    "Nomenclature:\n",
    " * **Experiment**: Show one of the two versions to a visitor.\n",
    " * **Observation**: Did the visitor click the ad.\n",
    " \n",
    "Minimize *regret* $R$ for $T$ experiments:\n",
    "$$R = T \\E[y^*] - \\sum_{t=1}^T y_t$$\n",
    " * $\\E[y^*]$ is the expected click rate for the better ad,\n",
    " * $y_t \\in \\{0,1\\}$ is whether visitor $t$, who was shown version $x_t \\in \\{A, B\\}$, clicked the ad.\n",
    "\n",
    " * Model click rates of $A$ and $B$ independently. Equations for A below.\n",
    " \n",
    "**Bayes theorem**: $p(\\theta \\mid \\mathcal{D}) = \\frac{p(\\mathcal{D} \\mid \\theta)}{p(\\mathcal{D})}  p(\\theta)$\n",
    "\n",
    "updates **prior** knowledge $p(\\theta)$ with **observations** $\\mathcal{D}$ to **posterior** knowledge $p(\\theta \\mid \\mathcal{D})$.\n",
    "\n",
    "Observation model:\n",
    "\n",
    "$$\\Pr(y_t \\mid x_t = A) = \\textrm{Bernoulli}(y_t \\mid \\rho_A) = \\rho_A^{y_t} (1 - \\rho_A)^{1-y_t}.$$\n",
    "\n",
    "Prior model:\n",
    "\n",
    "$$p(\\rho_A) = \\textrm{Beta}(\\rho_A \\mid \\alpha, \\beta) = \\frac{1}{B(\\alpha, \\beta)} \\rho_A^{\\alpha-1} (1 - \\rho_A)^{\\beta-1}.$$\n",
    "\n",
    "Given a dataset of $t$ observations $\\mathcal{D}_t = \\{(x_1, y_1), \\ldots, (x_t, y_t)\\}$, the posterior distribution is\n",
    "$$p(\\rho_A \\mid \\mathcal{D}_t) = \\frac{p(\\rho_A) \\prod_{t: x_t = A} \\Pr(y_t \\mid x_t = A)}{\\int_0^1 p(\\rho_A) \\prod_{t: x_t = A} \\Pr(y_t \\mid x_t = A) d\\rho_A} = \\textrm{Beta}(\\rho_B \\mid \\alpha + n^{A}_1, \\beta + n^{A}_0),$$\n",
    "where $n^{A}_1$ and $n^{A}_0$ are the total numbers of $y_t = 1$ and $y_t = 0$ for $x_t = A$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "x = np.linspace(0, 1, 101)\n",
    "\n",
    "plt.plot(x, scipy.stats.beta.pdf(x, 1, 1), 'b-', label='Prior Beta(1,1)')\n",
    "plt.xlabel(r'Click rate $\\rho_A$')\n",
    "plt.ylim(0, 2.5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(x, scipy.stats.beta.pdf(x, 1, 1), 'b-', label='Prior Beta(1,1)')\n",
    "plt.plot(x, x, 'r-', label='Observation model for y_1=1')\n",
    "plt.xlabel(r'Click rate $\\rho_A$')\n",
    "plt.ylim(0, 2.5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(x, scipy.stats.beta.pdf(x, 1, 1), 'b-', label='Prior Beta(1,1)')\n",
    "plt.plot(x, x, 'r-', label='Observation model for y_1=1')\n",
    "plt.plot(x, scipy.stats.beta.pdf(x, 2, 1), 'k-', label='Posterior Beta(2,1)')\n",
    "plt.xlabel(r'Click rate $\\rho_A$')\n",
    "plt.ylim(0, 2.5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(x, scipy.stats.beta.pdf(x, 1, 1), 'b-', label='Prior Beta(1,1)')\n",
    "plt.plot(x, scipy.stats.beta.pdf(x, 2, 5), 'k-', label='Posterior Beta(2,5)')\n",
    "plt.xlabel(r'Click rate $\\rho_A$')\n",
    "plt.ylim(0, 2.5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thompson sampling\n",
    "\n",
    "When $t+1$th visitor comes, which ad, $A$ or $B$, to serve?\n",
    "\n",
    " * Want to exploit: gather as much clicks as possible.\n",
    " * Need to explore: learn about click rates for $A$ and $B$.\n",
    " \n",
    "Thompson sampling is a simple algorithm navigating this trade-off:\n",
    "\n",
    " 1. Sample a value for $\\hat{\\rho}_A$ and for $\\hat{\\rho}_B$ from $p(\\rho_A \\mid \\mathcal{D}_t)$ and $p(\\rho_B \\mid \\mathcal{D}_t)$.\n",
    " 2. Show $A$ if $\\hat{\\rho}_A > \\hat{\\rho}_B$ and $B$ otherwise.\n",
    " \n",
    "We then observe whether the visitor clicked the ad or not and update our posterior distributions and continue to next iteration.\n",
    "\n",
    "## Example \n",
    "*How does Thompson sampling navigate exploration-exploitation trade-off?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rho_A_true = 0.1; rho_B_true = 0.2 # simulated visitor click rates\n",
    "alpha = 1; beta = 1 # prior parameters\n",
    "n_A1 = 0; n_A0 = 0; n_B1 = 0; n_B0 = 0 # numbers of clicks/no-clicks\n",
    "T = 1000 # number of iterations\n",
    "clicks = np.zeros(T); A_or_B = np.zeros(T)\n",
    "\n",
    "for t in range(T):\n",
    "    # Thompson sampling\n",
    "    rho_A = np.random.beta(alpha + n_A1, beta + n_A0)\n",
    "    rho_B = np.random.beta(alpha + n_B1, beta + n_B0)\n",
    "    if rho_A > rho_B: # which ad to show\n",
    "        y_t = np.random.binomial(1, rho_A_true) # simul. click\n",
    "        n_A1 += y_t; n_A0 += 1 - y_t; # update posterior of A\n",
    "    else:\n",
    "        y_t = np.random.binomial(1, rho_B_true) # simul. click\n",
    "        n_B1 += y_t; n_B0 += 1 - y_t; # update posterior of B\n",
    "    # collect statistics\n",
    "    clicks[t] = y_t; A_or_B[t] = rho_A > rho_B\n",
    "    \n",
    "# instead of Thompson sampling, allocate same numbers to A and B\n",
    "clicks_half = np.zeros(T)\n",
    "\n",
    "for t in range(T):\n",
    "    if t % 2 == 0:\n",
    "        y_t = np.random.binomial(1, rho_A_true)\n",
    "    else:\n",
    "        y_t = np.random.binomial(1, rho_B_true)\n",
    "    clicks_half[t] = y_t\n",
    "    \n",
    "plt.figure()\n",
    "plt.plot(range(1,T+1), np.cumsum(clicks), 'r-', label='Thompson sampling')\n",
    "plt.plot(np.array(range(1,T+1))[A_or_B==1], np.cumsum(clicks)[A_or_B==1], 'k.', label='Thompson sampling chose A')\n",
    "plt.plot(range(1,T+1), np.cumsum(clicks_half), 'b-', label='Half A, half B')\n",
    "plt.plot(range(1,T+1), np.array(range(1,T+1)) * rho_B_true, 'k-', label='Always B (theoretical average)')\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('Cumulative number of clicks')\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Bayesian Optimization\n",
    "\n",
    "## Task\n",
    "\n",
    "Find the minimum of a function $f(x)$ within some bounded domain $\\mathcal{X} \\subset \\mathbb{R}^D$:\n",
    "\n",
    "$$x^* = \\argmin_{x \\in \\mathcal{X}} f(x)$$\n",
    "\n",
    "Want to find the minimum with small number of evaluations of $f$.\n",
    "\n",
    " 1. **Construct a tractable statistical surrogate model of $f$.**\n",
    " 2. Turn the optimization problem into a sequence of easier problems.\n",
    "\n",
    "## Surrogate models\n",
    "\n",
    "\"A **surrogate model** is an engineering method used when an outcome of interest cannot be easily directly measured, so a model of the outcome is used instead.\" (Wikipedia)\n",
    " \n",
    "Let $g(x)$ be our **surrogate model** of $f$.\n",
    "\n",
    " * $g$ should be able to capture important aspects of $f$ from small number of evaluations.\n",
    " * Need to be able to update $g$ when we acquire new evaluations of $f$: $g$ should get better and better as a model of $f$.\n",
    " * $g$ should be fast to evaluate and to update.\n",
    " * $g$ needs to cope with noise.\n",
    " * Need to be able to quantify uncertainty in $g$ (navigating exploration-exploitation tradeoff).\n",
    "\n",
    "## Gaussian processes\n",
    "\n",
    "Gaussian process (GP) regression models are commonly used surrogate models used in BO. This is because of its capacity to approximate a large subset of model fit surfaces that are encountered in practice. GP models are also able to model the stochasticity of model fit, thus allowing a principled estimation of its mean and variance everywhere in the parameter search space.\n",
    "\n",
    " * Gaussian processes provide a probability distribution over functions.\n",
    " * Extends (and uses properties of) the multivariate normal distribution $\\Rightarrow$ computationally tractable.\n",
    " * Prior information about the type or behaviour of the modelled function can be included in the *covariance function* and its parameters.\n",
    " \n",
    " * Alternatives: random forests, Bayesian neural networks.\n",
    " \n",
    "<p>\n",
    "<div class=\"alert alert-block alert-success\"> \n",
    "<h3>In-class exercise.</h3> \n",
    "<br>\n",
    "Open the [Interactive demo app](http://www.tmpl.fi/bayesian-optimization/#37). Add observations to the plot. Then create a covariance function with a) length scale and b) noise parameters. Fiddle with the parameters to find the best combination. Length scale describes \"how close\" two points have to be to influence each other.</div>\n",
    "</p>\n",
    "<div id=\"gp-outer\"></div>\n",
    "\n",
    "\n",
    "## Turn the optimization problem into a sequence of easier problems\n",
    "\n",
    "Consider having evaluated $f$ at points $x_1, \\ldots, x_{t-1}$ and having constructed $p(g \\mid \\mathcal{D}_{t-1})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPy; import GPyOpt\n",
    "\n",
    "def f_u(x):\n",
    "    return x**2 + 0.1 + 0.1 * np.random.randn()\n",
    "bounds = [{'name': 'var_1', 'type': 'continuous', 'domain': (0,1)}]\n",
    "myBopt = GPyOpt.methods.BayesianOptimization(\n",
    "    f=f_u, domain=bounds, acquisition_type='EI',\n",
    "    exact_feval = False, initial_design_numdata=2, normalize_Y=False)\n",
    "max_iter = 0; max_time = 60; eps = 10e-6\n",
    "\n",
    "myBopt.run_optimization(max_iter, eps)\n",
    "myBopt._update_model()\n",
    "#myBopt.plot_acquisition()\n",
    "#myBopt.model.model.plot([0.0,1.0])\n",
    "model = myBopt.model.model\n",
    "\n",
    "x_grid = np.arange(0, 1, 0.001)\n",
    "x_grid = x_grid.reshape(len(x_grid),1)\n",
    "m, v = model.predict(x_grid)\n",
    "\n",
    "model.plot_density([0,1], alpha=.5)\n",
    "\n",
    "plt.plot(x_grid, m, 'k-',lw=1,alpha = 0.6)\n",
    "plt.plot(x_grid, m-1.96*np.sqrt(v), 'k-', alpha = 0.2)\n",
    "plt.plot(x_grid, m+1.96*np.sqrt(v), 'k-', alpha=0.2)\n",
    "\n",
    "Xdata, Ydata = myBopt.get_evaluations()\n",
    "\n",
    "plt.plot(Xdata, Ydata, 'r.', markersize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to choose the next $x$ to evaluate $f$ at?\n",
    "\n",
    "**What would you do?**\n",
    "\n",
    "Consider having evaluated $f$ at points $x_1, \\ldots, x_{t-1}$ and having constructed $p(g \\mid \\mathcal{D}_{t-1})$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "myBopt.plot_acquisition()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---- \n",
    "# 4. Acquisition functions \n",
    "How to choose the next $x$ to evaluate $f$ at?\n",
    "\n",
    "**Guided exploration** using $p(g \\mid \\mathcal{D}_{t-1})$:\n",
    "\n",
    " * Trade off exploration (reducing uncertainty) and exploitation (sampling near likely places of optima).\n",
    " * Formulated by maximizing an acquisition function $\\alpha(x; \\mathcal{D}_{t-1})$.\n",
    " \n",
    "$$x_{t} = \\argmax_x \\alpha(x; \\mathcal{D}_{t-1})$$\n",
    "\n",
    "**Thompson sampling** acquisition function:\n",
    "\n",
    " * $\\alpha(x; \\mathcal{D}_{t-1}) = \\hat{g}(x)$, where $\\hat{g}(x)$ is a sample from $p(g \\mid \\mathcal{D}_{t-1})$.\n",
    "\n",
    "**Expected improvement** acquisition function:\n",
    "\n",
    " * Currently best value $y^* = \\max_{s \\in \\{1,\\ldots,t-1\\}} y_s$.\n",
    " * Improvement function provides utility of $x$ given $g$: $I(x, g) = (g(x) - y^*) I(g(x) > y^*)$.\n",
    " * Expected improvement: $\\alpha_{EI}(x; \\mathcal{D}_t) = \\E_g[I(x, g)]$.\n",
    "\n",
    "Many others also exists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Optimization Recipe\n",
    "\n",
    "**Goal**: Find the minimum of a function $f(x)$ within some bounded domain $\\mathcal{X} \\subset \\mathbb{R}^D$:\n",
    "\n",
    "$$x^* = \\argmin_{x \\in \\mathcal{X}} f(x)$$\n",
    "\n",
    "**Key ideas**\n",
    "\n",
    " 1. Construct a tractable statistical surrogate model of $f$.\n",
    " 2. Turn the optimization problem into a sequence of easier problems.\n",
    "\n",
    "**Algorithm**\n",
    "\n",
    " 1. Initialize dataset $\\mathcal{D}_0$, surrogate model $p(g \\mid \\mathcal{D}_0)$; choose acquisition function $\\alpha(\\cdot)$.\n",
    " 2. Loop for $t = 1,2,\\ldots,T$:\n",
    "      1. Select next evaluation point: $x_{t} = \\argmax \\alpha(x; \\mathcal{D}_{t-1})$.\n",
    "      2. Evaluate $f(x_{t})$ to obtain $y_{t}$.\n",
    "      3. Update dataset $\\mathcal{D}_{t} = \\{\\mathcal{D}_{t-1},(x_t, y_t)\\}$.\n",
    "      4. Update surrogate model $p(g \\mid \\mathcal{D}_t)$.\n",
    " 3. Report the found optimum.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPyOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_u(x):\n",
    "    return 0.2 * (x - 0.3)**2 - 0.4 * np.sin(15.0 * x)\n",
    "\n",
    "plt.figure(); xx = np.linspace(0, 1, 101)\n",
    "plt.plot(xx, f_u(xx), 'k-'); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = [{'name': 'var_1', 'type': 'continuous', 'domain': (0,1)}]\n",
    "myBopt = GPyOpt.methods.BayesianOptimization(\n",
    "    f=f_u, domain=bounds,        # Function and domain                 \n",
    "    acquisition_type='EI',       # Expected improvement\n",
    "    exact_feval=True,            # Noiseless function evaluations\n",
    "    eps=1e-6,\n",
    "    normalize_Y=False,           # (for clearer visualization)\n",
    "    initial_design_numdata=2)    # (for clearer visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myBopt.run_optimization(max_iter=1)\n",
    "myBopt.plot_acquisition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myBopt.run_optimization(max_iter=1)\n",
    "myBopt.plot_acquisition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myBopt.run_optimization(max_iter=1)\n",
    "myBopt.plot_acquisition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myBopt.run_optimization(max_iter=1)\n",
    "myBopt.plot_acquisition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myBopt.run_optimization(max_iter=1)\n",
    "myBopt.plot_acquisition()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does it work?\n",
    "\n",
    " * Theoretical guarantees (regret bounds) exists under some conditions.\n",
    " * ''There is still a wide gap between theory and practice.'' - Shahriari et al.\n",
    "\n",
    "''[...]the careful choice of statistical model is often far more important than the choice of acquisition function heuristic.'' - Shahriari et al.\n",
    "\n",
    "**Some limitations**\n",
    "\n",
    " * Difficult for high-dimensional spaces.\n",
    " * Can spend a lot of time on the edges of the space (Siivola et al., MLSP 2018).\n",
    " * Computation complexity of inference in Gaussian processes scales as $O(N^3)$, where $N$ is the number of observations (sparse GPs/inducing point approximations can be used; or other types of models).\n",
    " * Optimizing hyperparameters (controlling the behaviour of the surrogate) can be challenging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 5. Application example\n",
    "\n",
    "Two types of rather direct human-in-the-loop applications:\n",
    " * Human provides explicit feedback at $x$, the value $f(x)$.\n",
    " * Human provides implicit feedback at $x$, for example, $f(x)$ is a completion time of a task with parameters $x$.\n",
    "\n",
    "## Animation design\n",
    "\n",
    "Find parameters for generating a procedural fluid animation:\n",
    "* velocity, radius and magnitude of the (possibly multiple) vortex rings,\n",
    "* length scale and magnitude of the curl noise,\n",
    "* relative strengths of vortex rings and curl noise.\n",
    "\n",
    "User can easily tell which animations look good: ''the psychoperceptual process underlying judgment - how well a realization fits what the user has in mind''.\n",
    "\n",
    "<div class=\"center\">\n",
    "<img src=\"imgs/anim.png\" style=\"width: 50%\" />\n",
    "</div>\n",
    "\n",
    "*Eric Brochu, Tyson Brochu, Nando de Freitas: A Bayesian Interactive Optimization Approach to Procedural Animation Design, Eurographics/ACM SIGGRAPH Symposium on Computer Animation (2010).*\n",
    "\n",
    "### User interface\n",
    "<div class=\"center\">\n",
    "<img src=\"imgs/ui.png\" style=\"width: 79%\" />\n",
    "</div>\n",
    "\n",
    "### Algorithm\n",
    "<div class=\"center\">\n",
    "<img src=\"imgs/bo_alg.png\" style=\"width: 79%\" />\n",
    "</div>\n",
    "\n",
    "### User study\n",
    " * Obtained improved results compared to novice and expert users setting parameters manually.\n",
    " * Tailored the Bayesian optimization approach to make it work:\n",
    "      1. preferential feedbacks,\n",
    "      2. transfer information over multiple sessions,\n",
    "      3. com-bined manual parameter tuning and Bayesian optimization.\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# In-class exercise: Eliciting color preferences\n",
    "\n",
    "<p>\n",
    "<div class=\"alert alert-block alert-success\"> \n",
    "<h3>In-class exercise.</h3> \n",
    "<br>\n",
    "Below is a script that implements the color preference elicitation problem. It asks 8 questions. Can you figure out how to improve it?  \n",
    "<br>\n",
    "<b>Tip:</b> Can you improve the acquisition function? Three things to try are: \n",
    "‘EI’, expected improvement;\n",
    "‘MPI’, maximum probability of improvement; and\n",
    "‘LCB’, GP-Lower confidence bound. \n",
    "[Manual page](https://gpyopt.readthedocs.io/en/latest/GPyOpt.methods.html)\n",
    "</div>\n",
    "</p>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def f_u(x):\n",
    "    plt.figure(1)\n",
    "    print(x)\n",
    "    im = x.reshape(1, 1, 3).repeat(3, axis=0).repeat(3, axis=1)\n",
    "    plt.imshow(im)\n",
    "    plt.show(block=False)\n",
    "    while True:\n",
    "        res = input('Grade? (0 to 5) ')\n",
    "        if res in ['0', '1', '2', '3', '4', '5']:\n",
    "            res = int(res)\n",
    "            plt.close(1)\n",
    "            return res\n",
    "\n",
    "\n",
    "def run_bo(max_iter):\n",
    "    bounds = [{'name': 'var_1', 'type': 'continuous', 'domain': (0, 1)},\n",
    "              {'name': 'var_2', 'type': 'continuous', 'domain': (0, 1)},\n",
    "              {'name': 'var_2', 'type': 'continuous', 'domain': (0, 1)}]\n",
    "    myBopt = GPyOpt.methods.BayesianOptimization(\n",
    "        f=f_u, domain=bounds,\n",
    "        acquisition_type='MPI',\n",
    "        exact_feval=False,\n",
    "        eps=1e-6,\n",
    "        normalize_Y=False,\n",
    "        initial_design_numdata=2,\n",
    "        maximize=True)\n",
    "    myBopt.run_optimization(max_iter=max_iter - 2)\n",
    "\n",
    "    return myBopt\n",
    "\n",
    "\n",
    "def run_random(max_iter):\n",
    "    xs = np.zeros((max_iter, 3))\n",
    "    ys = np.zeros((max_iter,))\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        xs[i, :] = np.random.rand(3)\n",
    "\n",
    "        ys[i] = f_u(xs[i, :])\n",
    "\n",
    "    return xs, ys\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    n_iter = 8\n",
    "    # run BO\n",
    "    bo = run_bo(n_iter)\n",
    "    # run random for comparison\n",
    "    ra = run_random(n_iter)\n",
    "\n",
    "    bo_xs, bo_ys = bo.get_evaluations()\n",
    "    ra_xs, ra_ys = ra\n",
    "\n",
    "    # one can investigate these to see how good colors were found and compare\n",
    "    # to a ground truth color\n",
    "\n",
    "    plt.plot(-bo_ys, 'k-', label='BO')\n",
    "    plt.plot(ra_ys, 'r-', label='Random')\n",
    "    plt.xlabel('iterations')\n",
    "    plt.ylabel('grades')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # let's say ground truth color was red\n",
    "    x_gt = np.array([1.0, 0.0, 0.0])\n",
    "\n",
    "    plt.plot(np.sqrt(np.sum((bo_xs - x_gt)**2, 1)), 'k-', label='BO')\n",
    "    plt.plot(np.sqrt(np.sum((ra_xs - x_gt)**2, 1)), 'r-', label='Random')\n",
    "    plt.xlabel('iterations')\n",
    "    plt.ylabel('distance from ground truth')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# 6. Conclusion \n",
    "\n",
    "## Summary\n",
    "Find the minimum of a function $f(x)$ within some bounded domain $\\mathcal{X} \\subset \\mathbb{R}^D$:\n",
    "\n",
    "$$x^* = \\argmin_{x \\in \\mathcal{X}} f(x)$$\n",
    "\n",
    " * $f$ is a black-box that we can only evaluate point-wise, \n",
    " * $f$ can be multi-modal,\n",
    " * $f$ is slow or expensive to evaluate,\n",
    " * evaluations of $f$ are noisy,\n",
    " * $f$ has no gradients available (can be used if available).\n",
    "\n",
    "**Key ideas**\n",
    "\n",
    " 1. Construct a tractable statistical surrogate model of $f$, with proper uncertainty quantification.\n",
    " 2. Turn the optimization problem into a sequence of easier problems, navigating the exploration-exploitation tradeoff.\n",
    "\n",
    "\n",
    "**Wide range of applications**. Relevant for HCI and human-in-the-loop modelling.\n",
    "\n",
    "Many **software implementations** (e.g., GPyOpt) exists. Relatively easy to start using.\n",
    "\n",
    "## Readings\n",
    " * <a href=\"https://ieeexplore.ieee.org/document/7352306\">Shahriari et al., **Taking the Human Out of the Loop: A Review of Bayesian Optimization**, Proceedings of the IEEE, 2016.</a>\n",
    " * <a href=\"http://nbviewer.jupyter.org/github/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/blob/master/Chapter1_Introduction/Ch1_Introduction_PyMC3.ipynb\">Cam Davidson-Pilon, **Chapter 1: Introduction to Bayesian Methods from Bayesian Methods for Hackers**.<a/>\n",
    " * <a href=\"http://www.gaussianprocess.org/gpml/\">Rasmussen, Williams, **Gaussian Processes for Machine Learning**, MIT Press, 2016.</a>\n",
    " * <a href=\"http://sheffieldml.github.io/GPyOpt/\">GPyOpt, Python package for Bayesian optimization.</a>\n",
    " * <a href=\"http://www.tmpl.fi/gp/\">Interactive Gaussian process regression demo.</a>\n",
    " * <a href=\"https://dl.acm.org/citation.cfm?id=1921443\">Brochu et al., **A Bayesian Interactive Optimization Approach to Procedural Animation Design**, Eurographics/ACM SIGGRAPH Symposium on Computer Animation, 2010.</a>.\n",
    " * <a href=\"https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0184054\">Kim et al., **Human-in-the-loop Bayesian optimization of wearable device parameters**, PLOS ONE, 2017.</a>\n",
    " * <a href=\"https://dl.acm.org/citation.cfm?doid=3025453.3025576\">Kangasraasio et al., **Inferring Cognitive Models from Data using Approximate Bayesian Computation**, CHI 2017.</a>\n",
    " * <a href=\"https://arxiv.org/abs/1704.00963\">Siivola et al., **Correcting boundary over-exploration deficiencies in Bayesian optimization with virtual derivative sign observations**, MLSP 2018.</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
